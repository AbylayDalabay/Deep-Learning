{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJdeTuGLz4eK"
   },
   "source": [
    "<h2></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sogpe4TSTQ_x"
   },
   "source": [
    "<h2>Your task is:</h2>\n",
    "<ul>\n",
    "  <li>Finish encoder (2 points)</li>\n",
    "  <li>Add decoder (3 points)</li>\n",
    "  <li>Replace saving function to visualisation (1 point)</li>\n",
    "</ul>\n",
    "<br> Please do not change the number of epoch to incrase quality of generation, possibly you will not have enough time,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kkM5ueDYmqb",
    "outputId": "16ed6ebb-e854-4f3b-9b63-36062fd7b711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "[0/5][0/391] Loss_D: 1.4126 Loss_G: 3.0209\n",
      "[0/5][100/391] Loss_D: 0.4212 Loss_G: 3.7976\n",
      "[0/5][200/391] Loss_D: 0.2289 Loss_G: 4.0345\n",
      "[0/5][300/391] Loss_D: 0.6261 Loss_G: 3.2202\n",
      "[1/5][0/391] Loss_D: 0.7986 Loss_G: 1.7975\n",
      "[1/5][100/391] Loss_D: 0.5808 Loss_G: 2.5497\n",
      "[1/5][200/391] Loss_D: 0.3369 Loss_G: 3.2090\n",
      "[1/5][300/391] Loss_D: 0.7791 Loss_G: 3.6145\n",
      "[2/5][0/391] Loss_D: 0.5101 Loss_G: 3.6225\n",
      "[2/5][100/391] Loss_D: 0.9757 Loss_G: 2.3579\n",
      "[2/5][200/391] Loss_D: 0.7118 Loss_G: 3.8935\n",
      "[2/5][300/391] Loss_D: 0.4214 Loss_G: 4.6231\n",
      "[3/5][0/391] Loss_D: 0.8119 Loss_G: 2.3780\n",
      "[3/5][100/391] Loss_D: 0.5161 Loss_G: 2.1721\n",
      "[3/5][200/391] Loss_D: 0.8338 Loss_G: 2.2319\n",
      "[3/5][300/391] Loss_D: 0.2831 Loss_G: 4.0873\n",
      "[4/5][0/391] Loss_D: 0.2925 Loss_G: 3.3062\n",
      "[4/5][100/391] Loss_D: 0.2146 Loss_G: 2.4185\n",
      "[4/5][200/391] Loss_D: 0.4851 Loss_G: 2.6131\n",
      "[4/5][300/391] Loss_D: 1.2232 Loss_G: 4.5151\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "lion_dataset = []\n",
    "for img, label in train_dataset:\n",
    "    if label == 7:  # Лев имеет метку 7 в CIFAR-10\n",
    "        lion_dataset.append((img, label))\n",
    "\n",
    "lion_loader = DataLoader(lion_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(#You code here, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(#You code here),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, #You code here, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(#You code here),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(128, #You code here, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(#You code here),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.main(z.view(z.size(0), self.latent_dim, 1, 1)).to('cuda')\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            #You code here\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.main(img).to('cuda')\n",
    "\n",
    "latent_dim = 100\n",
    "generator = Generator(latent_dim).to('cuda')\n",
    "discriminator = Discriminator().to('cuda')\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        real_imgs, _ = data\n",
    "        batch_size = real_imgs.size(0)\n",
    "        real_imgs = real_imgs.to('cuda')\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim, 1, 1).to('cuda')\n",
    "        fake_imgs = generator(z)\n",
    "        real_labels = torch.full((batch_size,), 1, dtype=torch.float, device='cuda')\n",
    "        fake_labels = torch.full((batch_size,), 0, dtype=torch.float, device='cuda')\n",
    "        real_output = discriminator(real_imgs).view(-1)\n",
    "        fake_output = discriminator(fake_imgs.detach()).view(-1)\n",
    "        real_loss = criterion(real_output, real_labels)\n",
    "        fake_loss = criterion(fake_output, fake_labels)\n",
    "        d_loss = #You code here sum of real and fake loss\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "        z = torch.randn(batch_size, latent_dim, 1, 1).to('cuda')\n",
    "        fake_imgs = generator(z)\n",
    "        output = discriminator(fake_imgs).view(-1)\n",
    "        g_loss = criterion(output, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(64, latent_dim, 1, 1).to('cuda')\n",
    "            fake_imgs = generator(z)\n",
    "            save_image(fake_imgs, f'generated_images/epoch_{epoch+1}.png', normalize=True)\n",
    "\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, num_epochs, i, len(train_loader), d_loss.item(), g_loss.item()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jU4dpdfZGnP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
